<a name="readme-top"></a>

<p align="center">
  <a href="https://anythingllm.com"><img src="https://github.com/Mintplex-Labs/anything-llm/blob/master/images/wordmark.png?raw=true" alt="AnythingLLM logo"></a>
</p>

<div align='center'>
<a href="https://trendshift.io/repositories/2415" target="_blank"><img src="https://trendshift.io/api/badge/repositories/2415" alt="Mintplex-Labs%2Fanything-llm | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a>
</div>

<p align="center">
    <b>AnythingLLM:</b> Enterprise-Grade Document Intelligence Platform<br />
    Full-stack AI platform for startups and enterprises with document-aware chat, AI agents, MCP integration, and embeddable widgets
</p>

<p align="center">
  <a href="https://discord.gg/6UyHPeGZAC" target="_blank">
      <img src="https://img.shields.io/badge/chat-mintplex_labs-blue.svg?style=flat&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAMAAABEpIrGAAAAIGNIUk0AAHomAACAhAAA+gAAAIDoAAB1MAAA6mAAADqYAAAXcJy6UTwAAAH1UExURQAAAP////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////r6+ubn5+7u7/3+/v39/enq6urq6/v7+97f39rb26eoqT1BQ0pOT4+Rkuzs7cnKykZKS0NHSHl8fdzd3ejo6UxPUUBDRdzc3RwgIh8jJSAkJm5xcvHx8aanqB4iJFBTVezt7V5hYlJVVuLj43p9fiImKCMnKZKUlaaoqSElJ21wcfT09O3u7uvr6zE0Nr6/wCUpK5qcnf7+/nh7fEdKTHx+f0tPUOTl5aipqiouMGtubz5CRDQ4OsTGxufn515hY7a3uH1/gXBydIOFhlVYWvX29qaoqCQoKs7Pz/Pz87/AwUtOUNfY2dHR0mhrbOvr7E5RUy8zNXR2d/f39+Xl5UZJSx0hIzQ3Odra2/z8/GlsbaGjpERHSezs7L/BwScrLTQ4Odna2zM3Obm7u3x/gKSmp9jZ2T1AQu/v71pdXkVISr2+vygsLiInKTg7PaOlpisvMcXGxzk8PldaXPLy8u7u7rm6u7S1tsDBwvj4+MPExbe4ueXm5s/Q0Kyf7ewAAAAodFJOUwAABClsrNjx/QM2l9/7lhmI6jTB/kA1GgKJN+nea6vy/MLZQYeVKK3rVA5tAAAAAWJLR0QB/wIt3gAAAAd0SU1FB+cKBAAmMZBHjXIAAAICSURBVDjLY2CAAkYmZhZWNnYODnY2VhZmJkYGVMDIycXNw6sBBbw8fFycyEoYGfkFBDVQgKAAPyMjQl5IWEQDDYgIC8FUMDKKsmlgAWyiEBWMjGJY5YEqxMAqGMWFNXAAYXGgAkYJSQ2cQFKCkYFRShq3AmkpRgYJbghbU0tbB0Tr6ukbgGhDI10gySfBwCwDUWBsYmpmDqQtLK2sbTQ0bO3sHYA8GWYGWWj4WTs6Obu4ami4OTm7exhqeHp5+4DCVJZBDmqdr7ufn3+ArkZgkJ+fU3CIRmgYWFiOARYGvo5OQUHhEUAFTkF+kVHRsLBgkIeyYmLjwoOc4hMSk5JTnINS06DC8gwcEEZ6RqZGlpOfc3ZObl5+gZ+TR2ERWFyBQQFMF5eklmqUpQb5+ReU61ZUOvkFVVXXQBSAraitq29o1GiKcfLzc29u0mjxBzq0tQ0kww5xZHtHUGeXhkZhdxBYgZ4d0LI6c4gjwd7siQQraOp1AivQ6CuAKZCDBBRQQQNQgUb/BGf3cqCCiZOcnCe3QQIKHNRTpk6bDgpZjRkzg3pBQTBrdtCcuZCgluAD0vPmL1gIdvSixUuWgqNs2YJ+DUhkEYxuggkGmOQUccskrioPTJCOXEnZ5JS5YslbGnuyVERlDDFvGEUPOWvwqaH6RVkHKeuDMK6SKnHlVhTgx8jeTmqy6Eij7K6nLqiGyPwChsa1MUrnq1wAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAyMy0xMC0wNFQwMDozODo0OSswMDowMB9V0a8AAAAldEVYdGRhdGU6bW9kaWZ5ADIwMjMtMTAtMDRUMDA6Mzg6NDkrMDA6MDBuCGkTAAAAKHRFWHRkYXRlOnRpbWVzdGFtcAAyMDIzLTEwLTA0VDAwOjM4OjQ5KzAwOjAwOR1IzAAAAABJRU5ErkJggg==" alt="Discord">
  </a> |
  <a href="https://github.com/Mintplex-Labs/anything-llm/blob/master/LICENSE" target="_blank">
      <img src="https://img.shields.io/static/v1?label=license&message=MIT&color=white" alt="License">
  </a> |
  <a href="https://docs.anythingllm.com" target="_blank">
    Docs
  </a> |
   <a href="https://my.mintplexlabs.com/aio-checkout?product=anythingllm" target="_blank">
    Hosted Instance
  </a>
</p>

<p align="center">
  <b>English</b> ¬∑ <a href='./locales/README.zh-CN.md'>ÁÆÄ‰Ωì‰∏≠Êñá</a> ¬∑ <a href='./locales/README.ja-JP.md'>Êó•Êú¨Ë™û</a>
</p>

<p align="center">
üëâ AnythingLLM for desktop (Mac, Windows, & Linux)! <a href="https://anythingllm.com/download" target="_blank"> Download Now</a>
</p>

---

## üìã Table of Contents

- [Overview](#overview)
- [Key Features](#key-features)
- [Enterprise Capabilities](#enterprise-capabilities)
- [Architecture](#architecture)
- [Deployment Options](#deployment-options)
- [Integration Capabilities](#integration-capabilities)
- [Security & Privacy](#security--privacy)
- [Quick Start](#quick-start)
- [Supported Providers](#supported-providers)
- [Documentation](#documentation)

---

## üéØ Overview

**AnythingLLM** is a production-ready, full-stack document intelligence platform designed for startups and enterprises. Transform any document, knowledge base, or content into an intelligent AI assistant that your team or customers can interact with through natural language conversations.

![Chatting](https://github.com/Mintplex-Labs/anything-llm/assets/16845892/cfc5f47c-bd91-4067-986c-f3f49621a859)

<details>
<summary><kbd>Watch the demo!</kbd></summary>

[![Watch the video](/images/youtube.png)](https://youtu.be/f95rGD9trL0)

</details>

### What Makes AnythingLLM Different?

- **üè¢ Enterprise-Ready**: Multi-user support, role-based permissions, audit logs, and SSO integration
- **üîå Fully Embeddable**: Deploy chat widgets on any website for customer-facing AI support
- **ü§ñ Advanced Agent System**: AI agents with MCP (Model Context Protocol) integration for Gmail, Calendar, LinkedIn, Google Drive, and custom tools
- **üîí Privacy-First**: Self-hosted option with complete data sovereignty - your documents never leave your infrastructure
- **‚ö° Production-Grade**: Built on proven technologies (Express, React, Prisma) with WebSocket support for real-time interactions
- **üé® Hyper-Configurable**: Swap LLMs, vector databases, embedders, and more without vendor lock-in

### Use Cases

#### For Startups
- **Customer Support Automation**: Embed AI chat widgets on your website trained on product documentation
- **Internal Knowledge Management**: Build private AI assistants for your team's internal wikis and documents
- **MVP Development**: Rapidly prototype AI features without building infrastructure from scratch
- **Cost-Effective AI**: Use open-source LLMs (Ollama, LMStudio) or affordable providers (TogetherAI, Groq)

#### For Enterprises
- **Department-Specific AI Assistants**: Create isolated workspaces for HR, Legal, Engineering, Sales teams
- **Client-Facing AI Solutions**: White-label embeddable chat for customer portals and support
- **Compliance & Security**: Self-hosted deployment with full audit trails and data governance
- **Legacy System Integration**: Connect existing documents, databases, and tools via MCP protocol
- **Multi-Workspace Architecture**: Separate contexts for different projects, teams, or clients with shared resources

---

## ‚ú® Key Features

### üìö Document Intelligence

#### Multi-Format Document Support
- **Supported Formats**: PDF, DOCX, TXT, CSV, JSON, Markdown, HTML, and more
- **Smart Chunking**: Optimized document parsing with intelligent context preservation
- **Large File Handling**: Process files up to 3GB (configurable)
- **Background Processing**: Asynchronous document ingestion via collector service

#### Vector Search & Embeddings
- **Semantic Search**: Find relevant information across documents using state-of-the-art embeddings
- **Vector Caching**: Cached embeddings for improved performance and reduced costs
- **Multiple Embedding Providers**:
  - AnythingLLM Native Embedder (default, free)
  - OpenAI, Azure OpenAI
  - LocalAI, Ollama, LM Studio (all models)
  - Cohere
- **Citation Tracking**: Every AI response includes source references for verification

### üí¨ Conversational AI

#### Real-Time Chat Experience
- **WebSocket Communication**: Real-time streaming responses for instant feedback
- **Context-Aware**: Maintains conversation history with workspace-specific context
- **Multi-Modal Support**: Text and image understanding (vision models supported)
- **Chat History**: Persistent conversation logs with search and export capabilities

#### Intelligent Responses
- **Document-Grounded Answers**: AI responses cite specific document sections
- **Clear Citations**: Source attribution for every piece of information
- **Conversation Threading**: Natural back-and-forth with context retention
- **Customizable System Prompts**: Configure AI personality and behavior per workspace

### ü§ñ Advanced Agent System

#### No-Code Agent Builder
- **Visual Workflow Builder**: Drag-and-drop interface for creating custom AI agent workflows
- **Agent Flows**: Create multi-step automated processes without code
- **Direct Output Mode**: Bypass LLM processing for deterministic responses when needed
- **Flow Library**: Save and reuse agent workflows across workspaces

#### Model Context Protocol (MCP) Integration
Full MCP compatibility for external tool integration:

- **üìß Gmail Integration**
  - Read and send emails
  - Search email history
  - Manage labels and threads

- **üìÖ Google Calendar**
  - Schedule and manage meetings
  - Check availability
  - Create calendar events

- **üëî LinkedIn**
  - Access profile information
  - Network insights

- **üìÅ Google Drive**
  - Access and search documents
  - Upload and download files
  - Folder management

- **üîß Custom MCP Servers**
  - Build your own integrations
  - Connect to internal APIs
  - Extend agent capabilities

#### Built-In Agent Skills
- **Memory**: Remember information across conversations
- **Web Scraping**: Extract information from websites
- **Document Summarization**: Generate summaries of long documents
- **Workflow Automation**: Execute multi-step processes
- **Universal Integrator**: Connect to external services via MCP

#### Function Calling Support
- **Native Support**: OpenAI, Anthropic Claude, Google Gemini
- **UnTooled Mode**: Natural language function calling for TogetherAI, LMStudio, Ollama (less reliable)
- **Custom Tools**: Build and register your own agent plugins

### üèóÔ∏è Workspace Architecture

#### Isolated Workspaces
- **Thread-Like Containers**: Each workspace is an isolated environment for documents and conversations
- **Shared Resources**: Documents can be shared across workspaces while maintaining conversation isolation
- **Per-Workspace Configuration**:
  - Custom LLM provider and model
  - Agent settings and skills
  - System prompts and behavior
  - User permissions and access control

#### Workspace Management
- **Create Unlimited Workspaces**: Organize by project, team, client, or use case
- **Document Sharing**: Add the same document to multiple workspaces without duplication
- **Bulk Operations**: Import/export conversations, documents, and settings
- **Search Across Workspaces**: Find information across all accessible workspaces

---

## üè¢ Enterprise Capabilities

### Multi-User Management & Permissions

#### Role-Based Access Control (RBAC)
- **Admin Role**: Full system access, user management, global settings
- **Manager Role**: Workspace creation, user assignments, document management
- **User Role**: Access assigned workspaces, chat capabilities

#### Granular Permissions
- **Workspace-Level Access**: Control who can view, edit, or delete specific workspaces
- **Document Permissions**: Restrict document access per user or role
- **Feature Flags**: Enable/disable features per workspace or user
- **API Access Control**: Manage programmatic access with API keys

#### User Provisioning
- **Built-in User Management**: Create, update, and delete users via UI or API
- **Session Management**: JWT-based authentication with configurable expiry (default: 30 days)
- **SSO Ready**: Architecture supports OAuth2 and SAML integration
- **Audit Logging**: Track user actions, logins, and permission changes

### Embeddable Chat Widgets (Docker Only)

Transform AnythingLLM into a customer-facing AI support tool:

#### Features
- **Website Integration**: Deploy with a simple script tag on any website
- **Customizable Branding**:
  - Custom colors and themes
  - Logo and branding
  - Welcome messages
  - UI customization
- **Multi-Workspace Support**: Different chat experiences for different pages/sections
- **Analytics Ready**: Track conversations, engagement, and AI performance
- **Responsive Design**: Works on desktop, tablet, and mobile

#### Use Cases
- Customer support chatbots on help centers
- Product documentation assistants
- Lead qualification and sales support
- Internal knowledge base access

[üìñ Learn more about embeddable chat widgets ‚Üí](https://github.com/Mintplex-Labs/anythingllm-embed/blob/main/README.md)

### Developer Tools & APIs

#### REST API
- **Full API Coverage**: Programmatic access to all AnythingLLM features
- **Authentication**: API key-based authentication for server-to-server communication
- **Endpoints**:
  - User and workspace management
  - Document upload and processing
  - Chat interactions
  - Agent invocation
  - System configuration
- **API Documentation**: OpenAPI/Swagger documentation available

#### Browser Extensions & Integrations
- **[Chrome Extension](https://github.com/Mintplex-Labs/anythingllm-extension)**: Save web pages directly to AnythingLLM workspaces
- **[Microsoft Word Add-in](https://gptlocalhost.com/demo/)**: Use AnythingLLM directly in Microsoft Word (via GPTLocalhost)
- **Custom Integrations**: Build your own tools using the REST API

#### Developer Features
- **Webhook Support**: Receive notifications for events (chat messages, document processing)
- **Custom Agent Plugins**: Extend agent capabilities with custom code
- **MCP Server Development**: Build custom MCP servers for specialized integrations
- **Local Development Tools**: Hot reload, debugging, and testing utilities

### Enterprise Deployment

#### Infrastructure Flexibility
- **Docker-First**: Official Docker images with docker-compose for easy orchestration
- **Cloud-Native**: Deploy on AWS, GCP, Azure, DigitalOcean, or any cloud provider
- **On-Premises**: Self-host on your infrastructure with full control
- **Desktop Apps**: Native applications for Mac, Windows, and Linux for individual users

#### Scalability & Performance
- **Horizontal Scaling**: Scale frontend, server, and collector independently
- **Load Balancing**: Built-in support for load-balanced deployments
- **Caching Strategy**: Vector embeddings cached for performance
- **Rate Limiting**: Protect your infrastructure with configurable rate limits
- **Background Jobs**: Document processing runs asynchronously

#### Data Sovereignty & Compliance
- **Self-Hosted Option**: All data stays on your servers - nothing leaves your infrastructure
- **GDPR Compliance**: Data deletion, user consent, and right-to-access workflows
- **Audit Trails**: Comprehensive logging of user actions, API calls, and data access
- **Encryption**: Data at rest and in transit encryption
- **Backup & Recovery**: Database backup and restore procedures

---

## üèóÔ∏è Architecture

AnythingLLM is built as a modern monorepo with three core services that work together to provide a complete AI platform.

### System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       Frontend (React + Vite)                ‚îÇ
‚îÇ  ‚Ä¢ Multi-user chat interface                                 ‚îÇ
‚îÇ  ‚Ä¢ Workspace management UI                                   ‚îÇ
‚îÇ  ‚Ä¢ Admin dashboard and settings                              ‚îÇ
‚îÇ  ‚Ä¢ Real-time WebSocket communication                         ‚îÇ
‚îÇ  ‚Ä¢ Responsive design (desktop, tablet, mobile)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ HTTP/WebSocket
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Server (Node.js + Express)                  ‚îÇ
‚îÇ  ‚Ä¢ REST API & WebSocket endpoints                           ‚îÇ
‚îÇ  ‚Ä¢ Authentication & authorization (JWT)                      ‚îÇ
‚îÇ  ‚Ä¢ LLM orchestration & function calling                      ‚îÇ
‚îÇ  ‚Ä¢ Vector database management                                ‚îÇ
‚îÇ  ‚Ä¢ Agent execution engine                                    ‚îÇ
‚îÇ  ‚Ä¢ MCP server integration                                    ‚îÇ
‚îÇ  ‚Ä¢ Session management                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ HTTP
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                Collector (Document Processor)                ‚îÇ
‚îÇ  ‚Ä¢ Multi-format document parsing                             ‚îÇ
‚îÇ  ‚Ä¢ Intelligent text chunking                                 ‚îÇ
‚îÇ  ‚Ä¢ Vector embedding generation                               ‚îÇ
‚îÇ  ‚Ä¢ Background job processing                                 ‚îÇ
‚îÇ  ‚Ä¢ File format conversion                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         Data Layer                           ‚îÇ
‚îÇ  ‚Ä¢ SQLite or PostgreSQL (primary database)                   ‚îÇ
‚îÇ  ‚Ä¢ LanceDB or other vector stores (embeddings)               ‚îÇ
‚îÇ  ‚Ä¢ Filesystem or S3 (document storage)                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Technology Stack

#### Backend Services
- **Runtime**: Node.js ‚â•18
- **Framework**: Express.js with WebSocket (socket.io)
- **ORM**: Prisma (supports SQLite and PostgreSQL)
- **Authentication**: JWT with configurable expiry
- **API**: RESTful endpoints + WebSocket for real-time communication

#### Frontend Application
- **Framework**: React 18
- **Build Tool**: Vite (fast development, optimized production builds)
- **State Management**: React Context API + local state
- **Real-Time**: WebSocket client for streaming responses
- **UI Components**: Custom component library with responsive design
- **Styling**: CSS modules and Tailwind CSS

#### Data Layer
- **Primary Database**:
  - SQLite (default) - Single-file database at `server/storage/anythingllm.db`
  - PostgreSQL (optional) - Configure via `DATABASE_URL` environment variable

- **Vector Storage** (choose one):
  - LanceDB (default) - Embedded vector database
  - Pinecone, Weaviate, Qdrant - Cloud-native vector databases
  - Chroma, ChromaCloud - Open-source and managed options
  - Milvus, Zilliz - Scalable vector databases
  - PGVector - PostgreSQL extension for vectors
  - Astra DB - Cassandra-based vector storage

- **File Storage**:
  - Local filesystem (default): `STORAGE_DIR` (default: `/server/storage/`)
  - S3-compatible storage (optional)

#### Database Schema

**Core Models**
- `User` - User accounts with roles (admin, manager, user)
- `Workspace` - Isolated containers for documents and chats
  - Includes `agentProvider` and `agentModel` columns for per-workspace agent config
- `WorkspaceChat` - Conversation history with message threading
- `Document` - Document metadata, vectorization status, and file paths
- `SystemSettings` - Global configuration and feature flags
- `WorkspaceAgentInvocation` - Agent execution tracking and results

### Agent Architecture

#### Agent Execution Flow

```
User Message (starts with @agent)
        ‚Üì
WebSocket Connection Established (/agent-invocation/:uuid)
        ‚Üì
Agent Handler (server/models/workspaceAgentInvocation.js)
        ‚Üì
Skills Registry (memory, webScraping, MCP tools, custom plugins)
        ‚Üì
LLM Function Calling (OpenAI/Anthropic/Gemini native or UnTooled mode)
        ‚Üì
Tool Execution (MCP servers, built-in plugins, custom functions)
        ‚Üì
Response Streaming (WebSocket with real-time updates)
        ‚Üì
Chat History Persistence (saved to database)
```

#### Agent Components

**1. Agent Triggering**
- Messages must start with `@agent` to invoke agent mode
- Detection logic: `/server/models/workspaceAgentInvocation.js::parseAgents()`
- WebSocket endpoint: `/server/endpoints/agentWebsocket.js`
- UUID-based session tracking

**2. Function Calling**
- **Native Support** (reliable): OpenAI, Anthropic Claude, Google Gemini
- **UnTooled Mode** (experimental): TogetherAI, LMStudio, Ollama
  - Uses natural language for function descriptions
  - Less reliable but enables more model options

**3. MCP Server Integration**
- Configuration: `/server/storage/plugins/anythingllm_mcp_servers_production.json`
- Universal MCP servers: Gmail, Google Calendar, LinkedIn, Google Drive
- Workspace detection priority:
  1. `args.workspaceId` (explicit parameter)
  2. `MCP_SERVER_NAME` environment variable
  3. `NANGO_CONNECTION_ID` for OAuth integrations

**4. Default Agent Skills**
- `memory` - Remember information across conversations
- `docSummarizer` - Summarize documents
- `webScraping` - Extract information from websites
- `universalIntegrator` - MCP tool integration
- `websocket` - Real-time communication
- `workflowCreator` - Build and execute workflows

**5. Custom Agent Plugins**
- Create plugins in `/server/utils/agents/aibitat/plugins/`
- Register in `/server/utils/agents/aibitat/plugins/index.js`
- Add to `DEFAULT_SKILLS` in `/server/utils/agents/defaults.js` for auto-enable

### Workspace Isolation Model

Each workspace operates as an isolated environment:

```
Workspace A                        Workspace B
‚îú‚îÄ Documents                       ‚îú‚îÄ Documents
‚îÇ  ‚îú‚îÄ Document 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚Üí Shared Document 1
‚îÇ  ‚îî‚îÄ Document 2                   ‚îÇ  ‚îî‚îÄ Document 3
‚îú‚îÄ Conversations (isolated)        ‚îú‚îÄ Conversations (isolated)
‚îú‚îÄ Agent Settings                  ‚îú‚îÄ Agent Settings
‚îÇ  ‚îú‚îÄ Provider: OpenAI             ‚îÇ  ‚îú‚îÄ Provider: Anthropic
‚îÇ  ‚îî‚îÄ Model: gpt-4o                ‚îÇ  ‚îî‚îÄ Model: claude-3-sonnet
‚îî‚îÄ Permissions                     ‚îî‚îÄ Permissions
```

**Key Benefits**:
- Documents can be shared across workspaces (deduplicated storage)
- Conversations remain isolated (no cross-workspace context leakage)
- Per-workspace LLM configuration
- Granular permission control

---

## üöÄ Deployment Options

### Docker Deployment (Recommended for Production)

Docker provides the most complete feature set including multi-user support and embeddable chat widgets.

#### Quick Start with Docker Compose

```bash
# Clone repository
git clone https://github.com/Mintplex-Labs/anything-llm.git
cd anything-llm/docker

# Configure environment
cp .env.example .env
# Edit .env file with your settings (JWT_SECRET, SIG_KEY, SIG_SALT, etc.)

# Start all services
docker-compose up -d

# Access AnythingLLM
# Default: http://localhost:3001
```

#### Docker Benefits
‚úÖ Multi-user support enabled
‚úÖ Embeddable chat widgets available
‚úÖ Easy updates and rollbacks
‚úÖ Production-ready configuration
‚úÖ Volume-based persistence
‚úÖ Environment-based configuration

[üìñ Complete Docker deployment guide ‚Üí](./docker/HOW_TO_USE_DOCKER.md)

### Cloud Deployments

One-click deployment to major cloud providers:

| Platform | One-Click Deploy | Notes |
|----------|------------------|-------|
| **AWS** | [![Deploy on AWS][aws-btn]][aws-deploy] | CloudFormation template included |
| **Google Cloud** | [![Deploy on GCP][gcp-btn]][gcp-deploy] | Cloud Run deployment |
| **DigitalOcean** | [![Deploy on DigitalOcean][do-btn]][do-deploy] | Terraform configuration |
| **Render** | [![Deploy on Render][render-btn]][render-deploy] | Managed platform |
| **Railway** | [![Deploy on Railway][railway-btn]][railway-deploy] | Managed platform |
| **RepoCloud** | [![Deploy on RepoCloud][repocloud-btn]][repocloud-deploy] | Managed platform |
| **Elestio** | [![Deploy on Elestio][elestio-btn]][elestio-deploy] | Managed hosting |

**Cloud Deployment Resources**:
- AWS: [CloudFormation Guide](./cloud-deployments/aws/cloudformation/DEPLOY.md)
- GCP: [Cloud Run Guide](./cloud-deployments/gcp/deployment/DEPLOY.md)
- DigitalOcean: [Terraform Guide](./cloud-deployments/digitalocean/terraform/DEPLOY.md)

### Bare Metal / VPS Deployment

Run AnythingLLM directly on any Linux/Mac/Windows server without Docker.

[üìñ Complete bare metal setup guide ‚Üí](./BARE_METAL.md)

**Quick Setup**:
```bash
# Install dependencies
yarn setup

# Configure environment
# Edit .env files in server/, frontend/, and collector/ directories

# Setup database
yarn prisma:setup

# Run in development
yarn dev:server     # Terminal 1 - Backend on port 3001
yarn dev:frontend   # Terminal 2 - Frontend on port 3000
yarn dev:collector  # Terminal 3 - Collector on port 8888

# Or run all services
yarn dev:all
```

### Desktop Applications

Native applications for individual users:

- **macOS**: Intel and Apple Silicon support
- **Windows**: Windows 10+ (64-bit)
- **Linux**: AppImage, Deb, and RPM packages

[üì• Download desktop apps ‚Üí](https://anythingllm.com/download)

**Desktop App Features**:
- Single-user mode (no authentication required)
- Local-first (all data stored locally)
- Built-in LLM providers
- System tray integration
- Auto-updates

### Managed Hosting

Don't want to manage infrastructure? Use the official hosted version:

[üåê Get a hosted instance ‚Üí](https://my.mintplexlabs.com/aio-checkout?product=anythingllm)

**Managed Hosting Includes**:
- Fully managed infrastructure
- Automatic updates
- Backups and disaster recovery
- Technical support
- SSL certificates
- Custom domains

---

## üîå Integration Capabilities

### Model Context Protocol (MCP)

AnythingLLM is one of the first platforms with full MCP integration, enabling seamless connection to external tools and services.

#### What is MCP?

The Model Context Protocol is a standardized way for LLMs to interact with external tools, databases, and APIs. Think of it as a universal adapter for AI agents.

#### Built-In MCP Servers

**Gmail MCP Server**
- Send and receive emails
- Search email history
- Manage labels and threads
- Auto-detect workspace context from email content

**Google Calendar MCP Server**
- Create and update calendar events
- Check availability
- Schedule meetings
- Time zone handling

**LinkedIn MCP Server**
- Access profile information
- View connections and network
- Read posts and updates
- (Note: Limited by LinkedIn API restrictions)

**Google Drive MCP Server**
- Search and access documents
- Upload and download files
- Folder management
- Workspace-aware file organization

#### Building Custom MCP Servers

Create your own MCP servers to connect AnythingLLM to internal systems:

```javascript
// Example MCP server structure
// Location: /server/your-custom-mcp.js

import { MCPServer } from '@modelcontextprotocol/sdk';

const server = new MCPServer({
  name: 'your-service',
  version: '1.0.0'
});

// Register tools
server.registerTool({
  name: 'your_tool_name',
  description: 'What your tool does',
  parameters: { /* JSON schema */ },
  handler: async (args) => {
    // Your tool logic
    return result;
  }
});

export default server;
```

Register in `/server/storage/plugins/anythingllm_mcp_servers_production.json`

[üìñ MCP Documentation ‚Üí](https://docs.anythingllm.com/mcp-compatibility/overview)

### REST API

Full programmatic access to all AnythingLLM features.

#### API Authentication

```bash
# API calls require authentication header
curl -X GET http://localhost:3001/api/workspaces \
  -H "Authorization: Bearer YOUR_API_KEY"
```

#### Common API Endpoints

**Workspace Management**
- `GET /api/workspaces` - List all workspaces
- `POST /api/workspaces` - Create workspace
- `GET /api/workspaces/:slug` - Get workspace details
- `PUT /api/workspaces/:slug` - Update workspace
- `DELETE /api/workspaces/:slug` - Delete workspace

**Document Management**
- `POST /api/documents/upload` - Upload document
- `GET /api/documents` - List documents
- `POST /api/workspaces/:slug/documents` - Add document to workspace
- `DELETE /api/workspaces/:slug/documents/:id` - Remove document

**Chat Interactions**
- `POST /api/workspaces/:slug/chat` - Send chat message
- `GET /api/workspaces/:slug/chats` - Get chat history
- `DELETE /api/workspaces/:slug/chats/:id` - Delete chat

**Agent Invocation**
- `POST /api/workspaces/:slug/agent` - Invoke agent (HTTP)
- `WS /agent-invocation/:uuid` - Agent WebSocket connection

**User Management** (Admin only)
- `GET /api/users` - List users
- `POST /api/users` - Create user
- `PUT /api/users/:id` - Update user
- `DELETE /api/users/:id` - Delete user

### Embeddable Chat Widget

Add AI chat to any website with a simple script tag.

#### Basic Implementation

```html
<!-- Add to your website's HTML -->
<script
  data-anythingllm-wid="your-workspace-slug"
  data-anythingllm-api-url="https://your-anythingllm-instance.com"
  src="https://your-anythingllm-instance.com/embed/anythingllm-chat-widget.min.js">
</script>
```

#### Customization Options

```html
<script
  data-anythingllm-wid="customer-support"
  data-anythingllm-api-url="https://ai.yourcompany.com"
  data-anythingllm-primary-color="#3B82F6"
  data-anythingllm-assistant-name="Support Assistant"
  data-anythingllm-assistant-icon="https://yoursite.com/logo.png"
  data-anythingllm-window-height="600px"
  data-anythingllm-window-width="400px"
  data-anythingllm-default-open="false"
  src="https://ai.yourcompany.com/embed/anythingllm-chat-widget.min.js">
</script>
```

[üìñ Complete embedding guide ‚Üí](https://github.com/Mintplex-Labs/anythingllm-embed/blob/main/README.md)

---

## üîí Security & Privacy

### Data Privacy

#### Self-Hosted Advantage
When self-hosted, AnythingLLM ensures:
- ‚úÖ Your documents never leave your infrastructure
- ‚úÖ All vector embeddings stored locally
- ‚úÖ Complete control over data access
- ‚úÖ No third-party data sharing

#### External API Calls
When using cloud LLM providers (OpenAI, Anthropic, etc.):
- Only selected document chunks are sent (not entire documents)
- Conversations are sent for context
- Consider using local models (Ollama, LMStudio) for complete privacy

### Authentication & Authorization

#### JWT-Based Authentication
- Secure token-based authentication
- Configurable token expiry (default: 30 days)
- Automatic token refresh
- Secure password hashing (bcrypt)

#### Role-Based Access Control
- Three built-in roles: Admin, Manager, User
- Per-workspace permission assignment
- Feature-level access control
- API key management for programmatic access

### Encryption

#### Data at Rest
- Database encryption (SQLite/PostgreSQL encryption options)
- File storage encryption (configurable)
- Vector database encryption (depends on provider)

#### Data in Transit
- HTTPS/TLS for all API communication
- WSS (WebSocket Secure) for real-time chat
- Secure cookie handling

### Compliance Features

#### GDPR Compliance
- **Right to Access**: Users can export all their data
- **Right to Deletion**: Complete data deletion capabilities
- **Data Portability**: Export conversations and documents
- **Consent Management**: User agreements and consent tracking

#### Audit Logging
- User authentication events
- Document access logs
- API call tracking
- Configuration changes
- Agent invocations and tool usage

#### Data Retention
- Configurable chat history retention
- Document expiry policies
- Automatic cleanup of expired data
- Backup and recovery procedures

### Telemetry & Privacy

AnythingLLM includes **optional** anonymous telemetry to help improve the product.

#### What is Collected (if enabled)
- Installation type (Docker or Desktop)
- Document added/removed events (no content)
- Vector database provider (no data)
- LLM provider and model tag (no prompts/responses)
- Chat message events (no content)

#### Opting Out
```bash
# Set in .env file
DISABLE_TELEMETRY=true

# Or disable in UI
Settings ‚Üí Privacy ‚Üí Disable Telemetry
```

**Important**:
- NO personally identifiable information is collected
- NO document content or chat messages are sent
- NO IP addresses are stored
- Telemetry provider: [PostHog](https://posthog.com/) (open-source)

[üìñ View all telemetry events in source code ‚Üí](https://github.com/search?q=repo%3AMintplex-Labs%2Fanything-llm%20.sendTelemetry\(&type=code)

---

## üöÄ Quick Start

### Prerequisites

- **Node.js**: Version 18 or higher
- **Yarn**: Package manager (install via `npm install -g yarn`)
- **Git**: For cloning the repository
- **Docker** (optional): For containerized deployment

### Local Development Setup

#### 1. Clone Repository

```bash
git clone https://github.com/Mintplex-Labs/anything-llm.git
cd anything-llm
```

#### 2. Setup Environment

```bash
# Install dependencies and create .env files
yarn setup
```

This creates `.env` files in:
- `/server/.env.development`
- `/frontend/.env`
- `/collector/.env`
- `/docker/.env`

#### 3. Configure Environment Variables

**Minimum Required Configuration** (`server/.env.development`):

```bash
# JWT Authentication (required)
JWT_SECRET=your-random-string-min-12-chars

# Signature keys (required)
SIG_KEY=your-passphrase-min-32-chars
SIG_SALT=your-salt-min-32-chars

# Server configuration
SERVER_PORT=3001
STORAGE_DIR=./storage

# Database (optional - defaults to SQLite)
# DATABASE_URL=postgresql://user:password@localhost:5432/anythingllm

# LLM Provider (optional - configure in UI)
# OPEN_AI_KEY=sk-...
# ANTHROPIC_API_KEY=sk-ant-...

# Embedding Provider (optional - uses built-in by default)
# EMBEDDING_ENGINE=openai
# EMBEDDING_MODEL=text-embedding-3-small
```

**Generate Secure Keys**:
```bash
# Generate random strings for JWT_SECRET, SIG_KEY, SIG_SALT
node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
```

#### 4. Setup Database

```bash
# Generate Prisma client and run migrations
yarn prisma:setup
```

This creates the SQLite database at `/server/storage/anythingllm.db`

#### 5. Start Development Servers

**Option A: Start All Services** (recommended)
```bash
yarn dev:all
```

**Option B: Start Services Separately** (for debugging)
```bash
# Terminal 1 - Backend API
yarn dev:server
# Runs on http://localhost:3001

# Terminal 2 - Frontend UI
yarn dev:frontend
# Runs on http://localhost:3000

# Terminal 3 - Document Collector
yarn dev:collector
# Runs on http://localhost:8888
```

#### 6. Access AnythingLLM

Open your browser to **http://localhost:3000**

**First-Time Setup**:
1. Create admin account
2. Configure LLM provider (or use built-in options)
3. Create your first workspace
4. Upload documents
5. Start chatting!

### Production Build

```bash
# Build frontend
yarn prod:frontend

# Start production server
yarn prod:server
```

### Docker Quick Start

```bash
cd docker
cp .env.example .env
# Edit .env file
docker-compose up -d
```

Access at **http://localhost:3001**

---

## üîß Supported Providers

AnythingLLM is provider-agnostic and supports a wide range of LLMs, embedding models, vector databases, and more.

### Large Language Models (LLMs)

#### Commercial Providers
- **[OpenAI](https://openai.com)** - GPT-4o, GPT-4o-mini, GPT-3.5-turbo
- **[Azure OpenAI](https://azure.microsoft.com/products/ai-services/openai-service)** - Azure-hosted OpenAI models
- **[Anthropic](https://www.anthropic.com/)** - Claude 3 Opus, Sonnet, Haiku
- **[Google Gemini](https://ai.google.dev/)** - Gemini Pro, Gemini Pro Vision
- **[AWS Bedrock](https://aws.amazon.com/bedrock/)** - Claude, Llama, Titan models
- **[Cohere](https://cohere.com/)** - Command models
- **[Mistral AI](https://mistral.ai/)** - Mistral models
- **[OpenRouter](https://openrouter.ai/)** - Access to 100+ models
- **[Perplexity](https://www.perplexity.ai/)** - Perplexity chat models
- **[DeepSeek](https://deepseek.com/)** - DeepSeek chat models
- **[xAI](https://x.ai/)** - Grok models
- **[NVIDIA NIM](https://build.nvidia.com/explore/discover)** - NVIDIA-hosted models
- **[Groq](https://groq.com/)** - Ultra-fast inference for Llama, Mixtral
- **[TogetherAI](https://www.together.ai/)** - Open-source models at scale
- **[Fireworks AI](https://fireworks.ai/)** - Fast inference for open models
- **[Novita AI](https://novita.ai/model-api/product/llm-api)** - LLM API
- **[PPIO](https://ppinfra.com)** - Decentralized AI infrastructure
- **[Moonshot AI](https://www.moonshot.ai/)** - Chinese LLM provider
- **[Apipie](https://apipie.ai/)** - LLM aggregator

#### Self-Hosted / Local Models
- **[Ollama](https://ollama.ai/)** - Run Llama 2, Mistral, and more locally
- **[LM Studio](https://lmstudio.ai)** - Desktop app for running local LLMs
- **[LocalAI](https://localai.io/)** - Self-hosted OpenAI-compatible API
- **[Text Generation Web UI](https://github.com/oobabooga/text-generation-webui)** - Web UI for running models
- **[KoboldCPP](https://github.com/LostRuins/koboldcpp)** - GGML model runner
- **[LiteLLM](https://github.com/BerriAI/litellm)** - Unified API for 100+ LLMs
- **[Hugging Face](https://huggingface.co/)** - Chat models via Inference API
- **OpenAI Generic** - Any OpenAI-compatible API
- **[llama.cpp Compatible Models](server/storage/models/README.md#text-generation-llm-selection)** - Run GGUF models directly

### Embedding Models

- **AnythingLLM Native Embedder** (default) - Free, built-in, no API key required
- **[OpenAI](https://openai.com)** - text-embedding-3-small, text-embedding-3-large
- **[Azure OpenAI](https://azure.microsoft.com/products/ai-services/openai-service)** - Azure-hosted embeddings
- **[Ollama](https://ollama.ai/)** - Local embedding models (all-minilm, nomic-embed-text)
- **[LM Studio](https://lmstudio.ai)** - Local embedding models
- **[LocalAI](https://localai.io/)** - Self-hosted embeddings
- **[Cohere](https://cohere.com/)** - Embed v3 models

### Vector Databases

- **[LanceDB](https://github.com/lancedb/lancedb)** (default) - Embedded vector database, zero config
- **[Pinecone](https://pinecone.io)** - Managed vector database
- **[Chroma](https://trychroma.com)** - Open-source vector database
- **[ChromaCloud](https://trychroma.com)** - Managed Chroma
- **[Weaviate](https://weaviate.io)** - Open-source vector database
- **[Qdrant](https://qdrant.tech)** - High-performance vector database
- **[Milvus](https://milvus.io)** - Scalable vector database
- **[Zilliz](https://zilliz.com)** - Managed Milvus
- **[PGVector](https://github.com/pgvector/pgvector)** - PostgreSQL extension
- **[Astra DB](https://www.datastax.com/products/datastax-astra)** - Cassandra-based vector DB

### Audio Transcription (Speech-to-Text)

- **AnythingLLM Built-in** (default) - Free, no API key required
- **[OpenAI Whisper API](https://openai.com/)** - Cloud-based transcription

### Text-to-Speech (TTS)

- **Native Browser Built-in** (default) - Uses browser's speech synthesis API
- **[PiperTTS](https://github.com/rhasspy/piper)** - Local, runs in browser
- **[OpenAI TTS](https://platform.openai.com/docs/guides/text-to-speech)** - Cloud-based TTS
- **[ElevenLabs](https://elevenlabs.io/)** - High-quality voice synthesis
- **OpenAI Compatible** - Any OpenAI-compatible TTS service

### Speech-to-Text (STT)

- **Native Browser Built-in** (default) - Uses browser's speech recognition API

---

## üìö Documentation

### Official Documentation
- **[Main Documentation](https://docs.anythingllm.com)** - Complete AnythingLLM documentation
- **[MCP Compatibility](https://docs.anythingllm.com/mcp-compatibility/overview)** - Model Context Protocol integration
- **[Agent Flows](https://docs.anythingllm.com/agent-flows/overview)** - No-code agent builder
- **[Custom AI Agents](https://docs.anythingllm.com/agent/custom/introduction)** - Build custom agent plugins

### GitHub Documentation
- **[CLAUDE.md](./CLAUDE.md)** - Architecture, development guide, and code conventions
- **[CONTRIBUTING.md](./CONTRIBUTING.md)** - How to contribute to AnythingLLM
- **[BARE_METAL.md](./BARE_METAL.md)** - Production setup without Docker
- **[Docker HOW TO](./docker/HOW_TO_USE_DOCKER.md)** - Docker deployment guide
- **[Documents Guide](./server/storage/documents/DOCUMENTS.md)** - Document processing details
- **[Vector Cache Guide](./server/storage/vector-cache/VECTOR_CACHE.md)** - Vector caching explained

### API & Integration Docs
- **REST API** - Full API documentation (coming soon)
- **[Embeddable Chat Widget](https://github.com/Mintplex-Labs/anythingllm-embed/blob/main/README.md)** - Widget integration guide
- **[Browser Extension](https://github.com/Mintplex-Labs/anythingllm-extension)** - Chrome extension docs

### Community Resources
- **[Discord Community](https://discord.gg/6UyHPeGZAC)** - Get help, share ideas, connect with other users
- **[GitHub Discussions](https://github.com/Mintplex-Labs/anything-llm/discussions)** - Q&A and feature requests
- **[GitHub Issues](https://github.com/Mintplex-Labs/anything-llm/issues)** - Bug reports and feature requests

---

## ü§ù External Apps & Integrations

*These are community-maintained integrations not officially supported by Mintplex Labs. A listing here is not an endorsement.*

- **[Midori AI Subsystem Manager](https://io.midori-ai.xyz/subsystem/anythingllm/)** - Streamlined Docker deployment tool
- **[Coolify](https://coolify.io/docs/services/anythingllm/)** - Deploy AnythingLLM with one click
- **[GPTLocalhost for Microsoft Word](https://gptlocalhost.com/demo/)** - Word Add-in for AnythingLLM integration

---

## üôè Contributing

We welcome contributions from the community! Whether you're fixing bugs, adding features, improving documentation, or spreading the word, we appreciate your help.

### How to Contribute

1. **Fork the repository**
2. **Create a feature branch** (`git checkout -b feature/amazing-feature`)
3. **Make your changes**
4. **Test thoroughly**
5. **Commit your changes** (`git commit -m 'Add amazing feature'`)
6. **Push to branch** (`git push origin feature/amazing-feature`)
7. **Open a Pull Request**

[üìñ Complete contribution guide ‚Üí](./CONTRIBUTING.md)

### Ways to Contribute

- üêõ **Report bugs** - Help us identify and fix issues
- üí° **Suggest features** - Share your ideas for improvements
- üìù **Improve documentation** - Help others understand AnythingLLM better
- üåç **Translate** - Add support for more languages
- üíª **Write code** - Contribute features, fixes, and improvements
- ‚≠ê **Star the repo** - Show your support and help others discover AnythingLLM

---

## üíñ Sponsors

### Premium Sponsors

<!-- premium-sponsors (reserved for $100/mth sponsors who request to be called out here and/or are non-private sponsors) -->
<a href="https://www.dcsdigital.co.uk" target="_blank">
  <img src="https://a8cforagenciesportfolio.wordpress.com/wp-content/uploads/2024/08/logo-image-232621379.png" height="100px" alt="User avatar: DCS DIGITAL" />
</a>
<!-- premium-sponsors -->

### All Sponsors

<!-- all-sponsors --><a href="https://github.com/jaschadub"><img src="https:&#x2F;&#x2F;github.com&#x2F;jaschadub.png" width="60px" alt="User avatar: Jascha" /></a><a href="https://github.com/KickingAss2024"><img src="https:&#x2F;&#x2F;github.com&#x2F;KickingAss2024.png" width="60px" alt="User avatar: KickAss" /></a><a href="https://github.com/ShadowArcanist"><img src="https:&#x2F;&#x2F;github.com&#x2F;ShadowArcanist.png" width="60px" alt="User avatar: ShadowArcanist" /></a><a href="https://github.com/AtlasVIA"><img src="https:&#x2F;&#x2F;github.com&#x2F;AtlasVIA.png" width="60px" alt="User avatar: Atlas" /></a><a href="https://github.com/cope"><img src="https:&#x2F;&#x2F;github.com&#x2F;cope.png" width="60px" alt="User avatar: Predrag Stojadinoviƒá" /></a><a href="https://github.com/DiegoSpinola"><img src="https:&#x2F;&#x2F;github.com&#x2F;DiegoSpinola.png" width="60px" alt="User avatar: Diego Spinola" /></a><a href="https://github.com/PortlandKyGuy"><img src="https:&#x2F;&#x2F;github.com&#x2F;PortlandKyGuy.png" width="60px" alt="User avatar: Kyle" /></a><a href="https://github.com/peperunas"><img src="https:&#x2F;&#x2F;github.com&#x2F;peperunas.png" width="60px" alt="User avatar: Giulio De Pasquale" /></a><a href="https://github.com/jasoncdavis0"><img src="https:&#x2F;&#x2F;github.com&#x2F;jasoncdavis0.png" width="60px" alt="User avatar: " /></a><a href="https://github.com/macstadium"><img src="https:&#x2F;&#x2F;github.com&#x2F;macstadium.png" width="60px" alt="User avatar: MacStadium" /></a><a href="https://github.com/armlynobinguar"><img src="https:&#x2F;&#x2F;github.com&#x2F;armlynobinguar.png" width="60px" alt="User avatar: " /></a><a href="https://github.com/MikeHago"><img src="https:&#x2F;&#x2F;github.com&#x2F;MikeHago.png" width="60px" alt="User avatar: " /></a><a href="https://github.com/maaisde"><img src="https:&#x2F;&#x2F;github.com&#x2F;maaisde.png" width="60px" alt="User avatar: " /></a><a href="https://github.com/mhollier117"><img src="https:&#x2F;&#x2F;github.com&#x2F;mhollier117.png" width="60px" alt="User avatar: " /></a><a href="https://github.com/pleabargain"><img src="https:&#x2F;&#x2F;github.com&#x2F;pleabargain.png" width="60px" alt="User avatar: Dennis" /></a><a href="https://github.com/broichan"><img src="https:&#x2F;&#x2F;github.com&#x2F;broichan.png" width="60px" alt="User avatar: Michael Hamilton, Ph.D." /></a><a href="https://github.com/azim-charaniya"><img src="https:&#x2F;&#x2F;github.com&#x2F;azim-charaniya.png" width="60px" alt="User avatar: " /></a><a href="https://github.com/gabriellemon"><img src="https:&#x2F;&#x2F;github.com&#x2F;gabriellemon.png" width="60px" alt="User avatar: TernaryLabs" /></a><a href="https://github.com/CelaDaniel"><img src="https:&#x2F;&#x2F;github.com&#x2F;CelaDaniel.png" width="60px" alt="User avatar: Daniel Cela" /></a><a href="https://github.com/altrsadmin"><img src="https:&#x2F;&#x2F;github.com&#x2F;altrsadmin.png" width="60px" alt="User avatar: Alesso" /></a><a href="https://github.com/bitjungle"><img src="https:&#x2F;&#x2F;github.com&#x2F;bitjungle.png" width="60px" alt="User avatar: Rune Mathisen" /></a><a href="https://github.com/pcrossleyAC"><img src="https:&#x2F;&#x2F;github.com&#x2F;pcrossleyAC.png" width="60px" alt="User avatar: " /></a><a href="https://github.com/saroj-pattnaik"><img src="https:&#x2F;&#x2F;github.com&#x2F;saroj-pattnaik.png" width="60px" alt="User avatar: " /></a><a href="https://github.com/techmedic5"><img src="https:&#x2F;&#x2F;github.com&#x2F;techmedic5.png" width="60px" alt="User avatar: Alan" /></a><a href="https://github.com/ddocta"><img src="https:&#x2F;&#x2F;github.com&#x2F;ddocta.png" width="60px" alt="User avatar: Damien Peters" /></a><a href="https://github.com/dcsdigital"><img src="https:&#x2F;&#x2F;github.com&#x2F;dcsdigital.png" width="60px" alt="User avatar: DCS Digital" /></a><a href="https://github.com/pm7y"><img src="https:&#x2F;&#x2F;github.com&#x2F;pm7y.png" width="60px" alt="User avatar: Paul Mcilreavy" /></a><a href="https://github.com/tilwolf"><img src="https:&#x2F;&#x2F;github.com&#x2F;tilwolf.png" width="60px" alt="User avatar: Til Wolf" /></a><a href="https://github.com/ozzyoss77"><img src="https:&#x2F;&#x2F;github.com&#x2F;ozzyoss77.png" width="60px" alt="User avatar: Leopoldo Crhistian Riverin Gomez" /></a><a href="https://github.com/AlphaEcho11"><img src="https:&#x2F;&#x2F;github.com&#x2F;AlphaEcho11.png" width="60px" alt="User avatar: AJEsau" /></a><a href="https://github.com/svanomm"><img src="https:&#x2F;&#x2F;github.com&#x2F;svanomm.png" width="60px" alt="User avatar: Steven VanOmmeren" /></a><a href="https://github.com/socketbox"><img src="https:&#x2F;&#x2F;github.com&#x2F;socketbox.png" width="60px" alt="User avatar: Casey Boettcher" /></a><a href="https://github.com/zebbern"><img src="https:&#x2F;&#x2F;github.com&#x2F;zebbern.png" width="60px" alt="User avatar: " /></a><a href="https://github.com/avineetbespin"><img src="https:&#x2F;&#x2F;github.com&#x2F;avineetbespin.png" width="60px" alt="User avatar: Avineet" /></a><a href="https://github.com/invictus-1"><img src="https:&#x2F;&#x2F;github.com&#x2F;invictus-1.png" width="60px" alt="User avatar: Chris" /></a><!-- all-sponsors -->

**Become a sponsor**: Support AnythingLLM development by [sponsoring the project](https://github.com/sponsors/Mintplex-Labs) ‚ù§Ô∏è

---

## üåü Contributors

[![anythingllm contributors](https://contrib.rocks/image?repo=mintplex-labs/anything-llm)](https://github.com/mintplex-labs/anything-llm/graphs/contributors)

---

## üìà Star History

[![Star History Chart](https://api.star-history.com/svg?repos=mintplex-labs/anything-llm&type=Timeline)](https://star-history.com/#mintplex-labs/anything-llm&Date)

---

## üîó More Products by Mintplex Labs

- **[VectorAdmin][vector-admin]:** All-in-one GUI & tool-suite for managing vector databases
- **[OpenAI Assistant Swarm][assistant-swarm]:** Turn your library of OpenAI assistants into a coordinated agent army

<div align="right">

[![][back-to-top]](#readme-top)

</div>

---

## üìÑ License

Copyright ¬© 2025 [Mintplex Labs][profile-link]. <br />
This project is [MIT](./LICENSE) licensed.

**MIT License Summary**: You can use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of AnythingLLM. The software is provided "as is", without warranty of any kind.

---

<!-- LINK GROUP -->

[back-to-top]: https://img.shields.io/badge/-BACK_TO_TOP-222628?style=flat-square
[profile-link]: https://github.com/mintplex-labs
[vector-admin]: https://github.com/mintplex-labs/vector-admin
[assistant-swarm]: https://github.com/Mintplex-Labs/openai-assistant-swarm
[docker-btn]: ./images/deployBtns/docker.png
[docker-deploy]: ./docker/HOW_TO_USE_DOCKER.md
[aws-btn]: ./images/deployBtns/aws.png
[aws-deploy]: ./cloud-deployments/aws/cloudformation/DEPLOY.md
[gcp-btn]: https://deploy.cloud.run/button.svg
[gcp-deploy]: ./cloud-deployments/gcp/deployment/DEPLOY.md
[do-btn]: https://www.deploytodo.com/do-btn-blue.svg
[do-deploy]: ./cloud-deployments/digitalocean/terraform/DEPLOY.md
[render-btn]: https://render.com/images/deploy-to-render-button.svg
[render-deploy]: https://render.com/deploy?repo=https://github.com/Mintplex-Labs/anything-llm&branch=render
[railway-btn]: https://railway.app/button.svg
[railway-deploy]: https://railway.app/template/HNSCS1?referralCode=WFgJkn
[repocloud-btn]: https://d16t0pc4846x52.cloudfront.net/deploylobe.svg
[repocloud-deploy]: https://repocloud.io/details/?app_id=276
[elestio-btn]: https://elest.io/images/logos/deploy-to-elestio-btn.png
[elestio-deploy]: https://elest.io/open-source/anythingllm